<!doctype html>
<html lang=en>

<head>
    <meta charset=UTF-8>
    <meta http-equiv=X-UA-Compatible content="IE=edge">
    <meta name=viewport content="width=device-width,initial-scale=1">
    <meta name=description content="Classifying photos of dogs and cats is a common task in the field of computer vision and machine learning. Whether you are building a pet recognition system">
    <meta name=keywords
        content="How to Classify Photos of Dogs and Cats, classification of cats and dogs using AI, artificial intelligence, ai project">
    <link rel=stylesheet href="/assets/css/style.css">
    <link rel="shortcut icon" href="/assets/img/logo.png" type=image/x-icon>
    <link rel="apple-touch-icon" href="/assets/img/logo.png">
    <title>How to Classify Photos of Dogs and Cats: A Comprehensive Guide</title>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GT5X9CH1KQ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-GT5X9CH1KQ');
    </script>
    <style>
        code pre {
            padding: .75rem;
            margin: 1.4rem 0;
            background-color: rgb(29, 26, 26);
            border-radius: 6px;
            color: whitesmoke;
            overflow-x: scroll;
        }
    </style>
</head>

<body>
    <nav class="bg-white shadow-md">
        <div class="container px-4 py-4 mx-auto">
            <div class="lg:flex lg:items-center">
                <div class="flex items-center justify-between">
                    <div><a class="text-xl font-bold text-gray-800 transition-colors duration-300 transform lg:text-xl hover:text-gray-700 flex items-center"
                            href= /><img src="/assets/img/logo.png" height=50 width=50 alt=""><span
                            class=px-2>UnicornCSS</span></a></div>
                    <div class="flex lg:hidden"><button x-cloak @click="isOpen = !isOpen" type=button
                            class="text-gray-500 hover:text-gray-600 focus:outline-none focus:text-gray-600"
                            aria-label="toggle menu"><svg x-show=!isOpen xmlns=http://www.w3.org/2000/svg
                                class="w-6 h-6 lg:hidden" id=ham fill=none viewBox="0 0 24 24" stroke=currentColor
                                stroke-width=2>
                                <path stroke-linecap=round stroke-linejoin=round d="M4 8h16M4 16h16" />
                            </svg></button></div>
                </div>
                <div class="absolute inset-x-0 z-20 flex-1 w-full px-6 py-4 transition-all duration-300 ease-in-out bg-white lg:mt-0 lg:p-0 lg:top-0 lg:relative lg:bg-transparent lg:w-auto lg:opacity-100 lg:translate-x-0 lg:flex lg:items-center lg:justify-between opacity-0 -translate-x-full"
                    id=nav>
                    <div
                        class="flex flex-col text-gray-600 capitalize lg:flex lg:px-16 lg:-mx-4 lg:flex-row lg:items-center">
                        <a href=/
                            class="mt-2 transition-colors duration-300 transform lg:mt-0 lg:mx-4 hover:text-gray-900">Home</a><a
                            href=/blog.html
                            class="mt-2 transition-colors duration-300 transform lg:mt-0 lg:mx-4 hover:text-gray-900">Blog</a><a
                            href=/about.html
                            class="mt-2 transition-colors duration-300 transform lg:mt-0 lg:mx-4 hover:text-gray-900">About</a><a
                            href=/contact.html
                            class="mt-2 transition-colors duration-300 transform lg:mt-0 lg:mx-4 hover:text-gray-900">Contact</a>
                    </div>
                    <div class="flex justify-center mt-6 lg:flex lg:mt-0 lg:-mx-2"><a href=#
                            class="mx-2 text-gray-600 transition-colors duration-300 transform hover:text-gray-500"
                            aria-label=Guthub><svg class="w-5 h-5 fill-current" viewBox="0 0 24 24" fill=none
                                xmlns=http://www.w3.org/2000/svg>
                                <path
                                    d="M12.026 2C7.13295 1.99937 2.96183 5.54799 2.17842 10.3779C1.395 15.2079 4.23061 19.893 8.87302 21.439C9.37302 21.529 9.55202 21.222 9.55202 20.958C9.55202 20.721 9.54402 20.093 9.54102 19.258C6.76602 19.858 6.18002 17.92 6.18002 17.92C5.99733 17.317 5.60459 16.7993 5.07302 16.461C4.17302 15.842 5.14202 15.856 5.14202 15.856C5.78269 15.9438 6.34657 16.3235 6.66902 16.884C6.94195 17.3803 7.40177 17.747 7.94632 17.9026C8.49087 18.0583 9.07503 17.99 9.56902 17.713C9.61544 17.207 9.84055 16.7341 10.204 16.379C7.99002 16.128 5.66202 15.272 5.66202 11.449C5.64973 10.4602 6.01691 9.5043 6.68802 8.778C6.38437 7.91731 6.42013 6.97325 6.78802 6.138C6.78802 6.138 7.62502 5.869 9.53002 7.159C11.1639 6.71101 12.8882 6.71101 14.522 7.159C16.428 5.868 17.264 6.138 17.264 6.138C17.6336 6.97286 17.6694 7.91757 17.364 8.778C18.0376 9.50423 18.4045 10.4626 18.388 11.453C18.388 15.286 16.058 16.128 13.836 16.375C14.3153 16.8651 14.5612 17.5373 14.511 18.221C14.511 19.555 14.499 20.631 14.499 20.958C14.499 21.225 14.677 21.535 15.186 21.437C19.8265 19.8884 22.6591 15.203 21.874 10.3743C21.089 5.54565 16.9181 1.99888 12.026 2Z">
                                </path>
                            </svg></a><a href=#
                            class="mx-2 text-gray-600 transition-colors duration-300 transform hover:text-gray-500"
                            aria-label=Facebook><svg class="w-5 h-5 fill-current" viewBox="0 0 24 24" fill=none
                                xmlns=http://www.w3.org/2000/svg>
                                <path
                                    d="M2.00195 12.002C2.00312 16.9214 5.58036 21.1101 10.439 21.881V14.892H7.90195V12.002H10.442V9.80204C10.3284 8.75958 10.6845 7.72064 11.4136 6.96698C12.1427 6.21332 13.1693 5.82306 14.215 5.90204C14.9655 5.91417 15.7141 5.98101 16.455 6.10205V8.56104H15.191C14.7558 8.50405 14.3183 8.64777 14.0017 8.95171C13.6851 9.25566 13.5237 9.68693 13.563 10.124V12.002H16.334L15.891 14.893H13.563V21.881C18.8174 21.0506 22.502 16.2518 21.9475 10.9611C21.3929 5.67041 16.7932 1.73997 11.4808 2.01722C6.16831 2.29447 2.0028 6.68235 2.00195 12.002Z">
                                </path>
                            </svg></a><a href=#
                            class="mx-2 text-gray-600 transition-colors duration-300 transform hover:text-gray-500"
                            aria-label=Instagram><svg class="w-5 h-5 fill-current" viewBox="0 0 24 24" fill=none
                                xmlns=http://www.w3.org/2000/svg>
                                <path
                                    d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z">
                                </path>
                            </svg></a></div>
                </div>
            </div>
        </div>
    </nav>
    <section class="my-8 w-11/12 mx-auto md:w-9/12 lg:w-7/12">
        <h1 class="text-3xl lg:text-4xl font-semibold mb-2">How to Classify Photos of Dogs and Cats: A Comprehensive Guide</h1>
        <p class="text-sm text-gray-600">Last modified - 19-05-2023</p>
        <hr class="my-3">
        <p>Classifying photos of dogs and cats is a common task in the field of computer vision and machine learning. Whether you are building a pet recognition system, developing an application for animal shelters, or simply exploring the world of image classification, understanding how to classify dogs and cats can serve as a great starting point. In this article, we will walk you through a step-by-step guide on how to classify photos of dogs and cats using machine learning techniques. We will cover the data collection process, feature extraction, model training, and evaluation. Additionally, we will provide sample code snippets in Python using popular libraries such as TensorFlow and scikit-learn to help you implement the classification system effectively.</p><p><br /></p><img src="/blog/imgs/20-1.png" alt="cats and dogs classification using ai"><div class="text-2xl font-semibold" style="text-align: left;">1. Data Collection and Preprocessing</div><p><br /></p><p>The first step in building an effective classification system is to gather a dataset of labeled images of dogs and cats. You can collect images from various sources, such as online repositories or by capturing your own photographs. Aim to collect a balanced dataset, with an equal number of images for each class.</p><p><br /></p><p>Once you have collected the images, it's crucial to preprocess them to ensure consistency and quality. Common preprocessing steps include resizing the images to a uniform size, converting them to grayscale or RGB format, and normalizing pixel values. Preprocessing can be done using libraries like OpenCV or PIL in Python.</p><p><br /></p><p class="text-2xl font-semibold">2. Feature Extraction</p><p><br /></p><p>Feature extraction plays a vital role in image classification. It involves transforming raw image data into meaningful and representative features that can be used by machine learning algorithms. In this section, we will explore two popular feature extraction techniques: Histogram of Oriented Gradients (HOG) and Convolutional Neural Networks (CNN).</p><p><br /></p><p>HOG is a traditional feature extraction method that calculates the distribution of gradients in an image. It captures shape and edge information, making it suitable for distinguishing between different animals. The scikit-image library in Python provides a simple implementation of HOG feature extraction.</p><p><br /></p><p>CNNs, on the other hand, are deep learning models that have achieved remarkable success in image classification tasks. They automatically learn hierarchical features from the images, eliminating the need for explicit feature extraction. Libraries like TensorFlow and Keras offer pre-trained CNN models, such as VGG16 or ResNet, which can be fine-tuned for our specific classification task.</p><p><br /></p><p class="text-2xl font-semibold">3. Model Training and Evaluation </p><p><br /></p><p>Once the features have been extracted, it's time to train a classification model using machine learning algorithms. In this section, we will focus on two widely used algorithms: Support Vector Machines (SVM) and Convolutional Neural Networks (CNN).</p><p><br /></p><p>SVM is a popular algorithm for image classification tasks. It separates different classes by finding an optimal hyperplane that maximally separates the data points. The scikit-learn library provides an implementation of SVM that can be trained on the extracted features.</p><p><br /></p><p>For CNN-based classification, we can either train the network from scratch or use a pre-trained model as a starting point. Fine-tuning a pre-trained model can save training time and improve performance. TensorFlow and Keras offer user-friendly APIs to build and train CNN models.</p><p><br /></p><p>Evaluation is an essential step to assess the performance of our classification system. Common evaluation metrics include accuracy, precision, recall, and F1 score. It's crucial to split the dataset into training and testing sets to measure the model's generalization capability accurately. Cross-validation techniques, such as k-fold cross-validation, can provide a robust estimate of the model's performance.</p><p><br /></p><p class="text-2xl font-semibold">Conclusion</p><p><br /></p><p>Classifying photos of dogs and cats is an exciting task that can serve as an excellent introduction to image classification. By following the step-by-step guide outlined in this article, you have learned the key aspects of building a classification system for dogs and cats. We covered the data collection process, preprocessing techniques, feature extraction methods, and model training using Support Vector Machines and Convolutional Neural Networks. Additionally, we discussed the importance of evaluating the model's performance using appropriate metrics.</p><p><br /></p><p>Implementing the classification system can be done using popular libraries such as TensorFlow, scikit-learn, Keras, and OpenCV in Python. With the provided code snippets and guidelines, you can start experimenting with your own dataset and fine-tune the process to achieve better results.</p><p><br /></p><p>Remember that image classification is an ongoing field of research, and there are always new techniques and advancements. Consider exploring more advanced architectures, such as attention mechanisms or transfer learning, to further enhance the accuracy of your classification system.</p><p><br /></p><p>Furthermore, you can extend the classification system by incorporating additional classes or implementing real-time predictions using computer vision techniques. This can open up possibilities for applications like automated pet identification, smart surveillance systems, or even interactive pet games.</p><p><br /></p><p>In conclusion, classifying photos of dogs and cats is a fascinating and practical application of machine learning and computer vision. By following the steps outlined in this article and experimenting with different techniques, you can develop a robust classification system capable of accurately identifying dogs and cats in images. Remember to iterate, evaluate, and refine your approach to achieve the best possible results. Happy classifying!</p><p><br /></p><p class="text-2xl font-semibold">Code Snippet:</p><p><br /></p>
        <code class="code">
            <pre><p># Import necessary libraries</p><p><span style="color: red;">import</span> cv2</p><p><span style="color: red;">import</span> numpy as np</p><p><span style="color: red;">from</span> skimage.feature <span style="color: red;">import</span> hog</p><p>from sklearn.svm import SVC</p><p><span style="color: red;">from</span> sklearn.model_selection <span style="color: red;">import</span> train_test_split</p><p><span style="color: red;">from</span> sklearn.metrics <span style="color: red;">import</span> accuracy_score</p><p><br /></p><p># Load and preprocess the dataset</p><p><span style="color: red;">def</span> <span style="color: #2b00fe;">preprocess_dataset</span>(images):</p><p>&nbsp; &nbsp; # Preprocess images here (e.g., resize, convert to grayscale, normalize)</p><p>&nbsp; &nbsp; preprocessed_images = []</p><p>&nbsp; &nbsp; <span style="color: red;">for</span> image <span style="color: red;">in</span> images:</p><p>&nbsp; &nbsp; &nbsp; &nbsp; # Preprocessing steps for each image</p><p>&nbsp; &nbsp; &nbsp; &nbsp; preprocessed_image = cv2.resize(image, (64, 64))</p><p>&nbsp; &nbsp; &nbsp; &nbsp; preprocessed_image = cv2.cvtColor(preprocessed_image, cv2.COLOR_BGR2GRAY)</p><p>&nbsp; &nbsp; &nbsp; &nbsp; preprocessed_image = preprocessed_image.astype(np.float32) / 255.0</p><p>&nbsp; &nbsp; &nbsp; &nbsp; preprocessed_images.append(preprocessed_image)</p><p>&nbsp; &nbsp; <span style="color: red;">return</span> preprocessed_images</p><p><br /></p><p># Extract HOG features from the images</p><p><span style="color: red;">def</span> <span style="color: #2b00fe;">extract_hog_features</span>(images):</p><p>&nbsp; &nbsp; hog_features = []</p><p>&nbsp; &nbsp; <span style="color: red;">for</span> image <span style="color: red;">in</span> images:</p><p>&nbsp; &nbsp; &nbsp; &nbsp; hog_feature = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)</p><p>&nbsp; &nbsp; &nbsp; &nbsp; hog_features.append(hog_feature)</p><p>&nbsp; &nbsp; <span style="color: red;">return</span> hog_features</p><p><br /></p><p># Train an SVM model on the extracted features</p><p><span style="color: red;">def</span> <span style="color: #2b00fe;">train_svm</span>(features, labels):</p><p>&nbsp; &nbsp; X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)</p><p>&nbsp; &nbsp; svm = SVC()</p><p>&nbsp; &nbsp; svm.fit(X_train, y_train)</p><p>&nbsp; &nbsp; y_pred = svm.predict(X_test)</p><p>&nbsp; &nbsp; accuracy = accuracy_score(y_test, y_pred)</p><p>&nbsp; &nbsp; <span style="color: red;">return</span> svm, accuracy</p><p><br /></p><p># Example usage</p><p># Load and preprocess the dataset</p><p>dog_images = load_dog_images()&nbsp; # Load dog images</p><p>cat_images = load_cat_images()&nbsp; # Load cat images</p><p><br /></p><p>dog_images_preprocessed = preprocess_dataset(dog_images)</p><p>cat_images_preprocessed = preprocess_dataset(cat_images)</p><p><br /></p><p># Extract HOG features from the images</p><p>dog_features = extract_hog_features(dog_images_preprocessed)</p><p>cat_features = extract_hog_features(cat_images_preprocessed)</p><p><br /></p><p># Combine features and labels</p><p>features = dog_features + cat_features</p><p>labels = [1] * <span style="color: #ffa400;">len</span>(dog_features) + [0] * <span style="color: #ffa400;">len</span>(cat_features)</p><p><br /></p><p># Train the SVM model</p><p>svm_model, accuracy = train_svm(features, labels)</p><p><br /></p><p># Evaluate the model</p><p><span style="color: #ffa400;">print</span>("Accuracy: {:.2f}%".format(accuracy * 100))</p><p></p><p><br /></p></pre></code>
        
        <p>Note:</p><p><br /></p><p>The code snippet provided above demonstrates an example implementation for classifying photos of dogs and cats using the Histogram of Oriented Gradients (HOG) feature extraction technique and the Support Vector Machine (SVM) algorithm. However, please note that the code is only a simplified representation to showcase the key steps involved and may require modifications based on your specific dataset and requirements.</p><p><br /></p><p>To further enhance the classification system, you can explore other feature extraction techniques, such as deep learning-based methods like Convolutional Neural Networks (CNNs). Libraries like TensorFlow and Keras provide pre-trained CNN models that can be fine-tuned for your specific classification task.</p><p><br /></p><p>Here's an example code snippet for training a simple CNN model using TensorFlow and Keras:</p><p><br /></p>
        <code class="code"><pre><p><span style="color: red;">import</span> tensorflow <span style="color: red;">as</span> tf</p><p><span style="color: red;">from</span> tensorflow.keras.models <span style="color: red;">import</span> Sequential</p><p><span style="color: red;">from</span> tensorflow.keras.layers <span style="color: red;">import</span> Conv2D, MaxPooling2D, Flatten, Dense</p><p><br /></p><p># Define the CNN model</p><p>model = Sequential()</p><p>model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))</p><p>model.add(MaxPooling2D((2, 2)))</p><p>model.add(Conv2D(64, (3, 3), activation='relu'))</p><p>model.add(MaxPooling2D((2, 2)))</p><p>model.add(Flatten())</p><p>model.add(Dense(64, activation='relu'))</p><p>model.add(Dense(1, activation='sigmoid'))</p><p><br /></p><p># Compile the model</p><p>model.<span style="color: #ffa400;">compile</span>(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</p><p><br /></p><p># Preprocess the dataset</p><p>dog_images_preprocessed = preprocess_dataset(dog_images)</p><p>cat_images_preprocessed = preprocess_dataset(cat_images)</p><p><br /></p><p># Combine and label the images</p><p>images = np.array(dog_images_preprocessed + cat_images_preprocessed)</p><p>labels = np.array([1] * len(dog_images_preprocessed) + [0] * len(cat_images_preprocessed))</p><p><br /></p><p># Split the dataset into training and testing sets</p><p>X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)</p><p><br /></p><p># Reshape the data to match the input shape of the CNN model</p><p>X_train = X_train.reshape(X_train.shape[0], 64, 64, 1)</p><p>X_test = X_test.reshape(X_test.shape[0], 64, 64, 1)</p><p><br /></p><p># Train the CNN model</p><p>model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))</p><p><br /></p><p># Evaluate the model</p><p>_, accuracy = model.evaluate(X_test, y_test)</p><p><span style="color: #ffa400;">print</span>("Accuracy: {:.2f}%".format(accuracy * 100))</p></pre></code>
        <p></p><p><br /></p><p>In the code above, we define a simple CNN model architecture using TensorFlow and Keras. We compile the model with an optimizer, loss function, and evaluation metric. We preprocess the dataset, combine the images, and assign labels. Then, we split the dataset into training and testing sets. After reshaping the data to match the input shape of the CNN model, we train the model using the training data. Finally, we evaluate the model's accuracy on the testing data.</p><p><br /></p><p>Remember to customize the code according to your dataset structure, preprocessing requirements, and desired model architecture. Experimenting with different CNN architectures, hyperparameters, and data augmentation techniques can help improve the classification accuracy.</p><p><br /></p><p>With this comprehensive guide and the provided code snippets, you should have a solid foundation to classify photos of dogs and cats using different techniques and algorithms. Happy coding!</p><p></p>
    </section>
    <footer class="flex flex-col items-center justify-between p-6 bg-white sm:flex-row">
        <a href=/
            class="text-xl font-bold text-gray-600 transition-colors duration-300 hover:text-gray-700 flex items-center"><img
                src="/assets/img/logo.png" height=50 width=50 alt=""><span class=px-2>UnicornCSS</span></a>
        <div class="flex flex-col md:flex-row items-center justify-between">
            <p class="text-sm text-gray-600">© Copyright 2021. All Rights Reserved</p><a class="text-gray-500 px-2"
                href=/privacy-policy.html>Privacy-policy</a><a class=text-gray-500 href=/dmca.html>DMCA</a>
        </div>
        <div class="flex -mx-2 mt-2 lg:mt-0"><a href=#
                class="mx-2 text-gray-600 transition-colors duration-300 hover:text-blue-500" aria-label=Github><svg
                    class="w-5 h-5 fill-current" viewBox="0 0 24 24" fill=none xmlns=http://www.w3.org/2000/svg>
                    <path
                        d="M12.026 2C7.13295 1.99937 2.96183 5.54799 2.17842 10.3779C1.395 15.2079 4.23061 19.893 8.87302 21.439C9.37302 21.529 9.55202 21.222 9.55202 20.958C9.55202 20.721 9.54402 20.093 9.54102 19.258C6.76602 19.858 6.18002 17.92 6.18002 17.92C5.99733 17.317 5.60459 16.7993 5.07302 16.461C4.17302 15.842 5.14202 15.856 5.14202 15.856C5.78269 15.9438 6.34657 16.3235 6.66902 16.884C6.94195 17.3803 7.40177 17.747 7.94632 17.9026C8.49087 18.0583 9.07503 17.99 9.56902 17.713C9.61544 17.207 9.84055 16.7341 10.204 16.379C7.99002 16.128 5.66202 15.272 5.66202 11.449C5.64973 10.4602 6.01691 9.5043 6.68802 8.778C6.38437 7.91731 6.42013 6.97325 6.78802 6.138C6.78802 6.138 7.62502 5.869 9.53002 7.159C11.1639 6.71101 12.8882 6.71101 14.522 7.159C16.428 5.868 17.264 6.138 17.264 6.138C17.6336 6.97286 17.6694 7.91757 17.364 8.778C18.0376 9.50423 18.4045 10.4626 18.388 11.453C18.388 15.286 16.058 16.128 13.836 16.375C14.3153 16.8651 14.5612 17.5373 14.511 18.221C14.511 19.555 14.499 20.631 14.499 20.958C14.499 21.225 14.677 21.535 15.186 21.437C19.8265 19.8884 22.6591 15.203 21.874 10.3743C21.089 5.54565 16.9181 1.99888 12.026 2Z">
                    </path>
                </svg></a><a href=# class="mx-2 text-gray-600 transition-colors duration-300 hover:text-blue-500"
                aria-label=Facebook><svg class="w-5 h-5 fill-current" viewBox="0 0 24 24" fill=none
                    xmlns=http://www.w3.org/2000/svg>
                    <path
                        d="M2.00195 12.002C2.00312 16.9214 5.58036 21.1101 10.439 21.881V14.892H7.90195V12.002H10.442V9.80204C10.3284 8.75958 10.6845 7.72064 11.4136 6.96698C12.1427 6.21332 13.1693 5.82306 14.215 5.90204C14.9655 5.91417 15.7141 5.98101 16.455 6.10205V8.56104H15.191C14.7558 8.50405 14.3183 8.64777 14.0017 8.95171C13.6851 9.25566 13.5237 9.68693 13.563 10.124V12.002H16.334L15.891 14.893H13.563V21.881C18.8174 21.0506 22.502 16.2518 21.9475 10.9611C21.3929 5.67041 16.7932 1.73997 11.4808 2.01722C6.16831 2.29447 2.0028 6.68235 2.00195 12.002Z">
                    </path>
                </svg></a><a href=# class="mx-2 text-gray-600 transition-colors duration-300 hover:text-blue-500"
                aria-label=Reddit><svg class="w-5 h-5 fill-current" viewBox="0 0 24 24" fill=none
                    xmlns=http://www.w3.org/2000/svg>
                    <path
                        d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z">
                    </path>
                </svg></a></div>
    </footer>
    <script src="/assets/js/script.js"></script>
</body>

</html>